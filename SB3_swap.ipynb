{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpesceKU/PeptDes/blob/main/SB3_swap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tlVupjLyCNyL"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra] localcider==0.1.18 >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT6Pdf5LDAJh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from localcider.sequenceParameters import SequenceParameters\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ7rn5kJCsnr"
      },
      "outputs": [],
      "source": [
        "class PeptDes_SWAP(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define action and observation space\n",
        "        # They must be gym.spaces objects\n",
        "        # Example when using discrete actions:\n",
        "        #self.max_episode_steps = 200\n",
        "        self.alphabet = np.array(list(\"ARNDCQEGHILKMFPSTWYV\")).reshape(-1, 1)\n",
        "        self.enc = OneHotEncoder(handle_unknown='ignore').fit(self.alphabet)\n",
        "        self.initial_state = 'MASASSSQRGRSGSGNFGGGRGGGFGGNDNFGRGGNFSGRGGFGGSRGGGGYGGSGDGYNGFGNDGSNFGGGGSYNDFGNYNNQSSNFGPMKGGNFGGRSSGGSGGGGQYFAKPRNQGGYGGSSSSSSYGSGRRF'\n",
        "        self.current_seq = list('MASASSSQRGRSGSGNFGGGRGGGFGGNDNFGRGGNFSGRGGFGGSRGGGGYGGSGDGYNGFGNDGSNFGGGGSYNDFGNYNNQSSNFGPMKGGNFGGRSSGGSGGGGQYFAKPRNQGGYGGSSSSSSYGSGRRF')\n",
        "        self.L = int(len(self.initial_state))\n",
        "        self.target = 0.75\n",
        "\n",
        "        self.action_space = spaces.MultiDiscrete(np.array([self.L,self.L]))\n",
        "        self.observation_space = spaces.MultiBinary([self.L, 20])\n",
        "        #self.observation_space = spaces.Box(low=0, high=1, shape=(self.L, 20), dtype=int)\n",
        "        #self.observation_space = spaces.Text(min_length=self.L, max_length=self.L, charset='ARNDCQEGHILKMFPSTWYV', seed=13)\n",
        "        #self.observation_space = spaces.MultiDiscrete(np.array([2]*20*self.L))\n",
        "        self.episode_length = -1\n",
        "\n",
        "    def logger(self, message):\n",
        "        out = open(f'worker_{threading.get_ident()}.dat','a+')\n",
        "        out.write(message)\n",
        "        out.close()\n",
        "\n",
        "    def fwd_onehot(self, seq):\n",
        "        return self.enc.transform(np.array(seq).reshape(-1, 1)).toarray()\n",
        "    def score_prot(self):\n",
        "        SeqOb = SequenceParameters(''.join(self.current_seq))\n",
        "        return SeqOb.get_kappa()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Convert the protein sequence to one-hot encoding\n",
        "        observation = self.fwd_onehot(self.current_seq)\n",
        "\n",
        "        info = {}\n",
        "\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_seq[action[1]], self.current_seq[action[0]] = self.current_seq[action[0]], self.current_seq[action[1]]\n",
        "        # Calculate the new score\n",
        "        score = self.score_prot()\n",
        "        s = ''.join(self.current_seq)\n",
        "        self.logger(message=f'{s} {action[0]} {action[1]} {score}\\n')\n",
        "\n",
        "      \t# Determine the termination flag\n",
        "        terminated = True\n",
        "\n",
        "        reward = -abs(score - self.target)\n",
        "\n",
        "      \t# Prepare the new observation\n",
        "        new_observation = self.fwd_onehot(self.current_seq)\n",
        "\n",
        "        info = {'score':score}\n",
        "\n",
        "        return new_observation, reward, terminated, False, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaPT73GCDhzF"
      },
      "outputs": [],
      "source": [
        "vec_env = make_vec_env(PeptDes_SWAP, n_envs=1)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", vec_env, learning_rate=0.001, n_steps=64, gae_lambda=0.01, verbose=2)\n",
        "\n",
        "print(model.policy)\n",
        "\n",
        "model.learn(total_timesteps=64*50, progress_bar=True)\n",
        "#model.save(\"ppo\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM3+n7X3X9mozqC/qS9tHsn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}